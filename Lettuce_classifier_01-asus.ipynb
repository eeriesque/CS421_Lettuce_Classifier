{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ace3ccdb",
   "metadata": {},
   "source": [
    "# Lettuce Classification Model\n",
    "#### Developers: ANVI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a493d371",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1d5f1358",
   "metadata": {},
   "source": [
    "### Import Libraries and Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4edd0621",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip install tensorflow\n",
    "# import tensorflow as tf\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "198a939e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import io\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b515b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D, Flatten, Dense, Dropout, BatchNormalization\n",
    "from tensorflow.keras.losses import SparseCategoricalCrossentropy\n",
    "from tensorflow.keras.preprocessing import image_dataset_from_directory\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.layers.experimental.preprocessing import RandomFlip, RandomRotation, RandomZoom, CenterCrop, Rescaling, Resizing\n",
    "from tensorflow.data import AUTOTUNE\n",
    "from tensorflow import cast, int64"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae3a6f0f",
   "metadata": {},
   "source": [
    "### Load Data\n",
    "\n",
    "Setting Directory Paths Accordingly. \n",
    "  \n",
    " We split the training, validation, and test dataset.\n",
    "    \n",
    "    (1) Training Dataset is used to train the neural network directly. The dataset is partitioned by 8:2.\n",
    "    (2) Validation Dataset is used during the training to assess the performance of the network at various iterations.\n",
    "    (3) Test Dataset is either a partition of the dataset or the a new dataset entirely that evaluates the performance of our network after completion of the training phase.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3634a8d8",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "path = os.path.abspath(os.getcwd())\n",
    "test_path, train_path, og_path = path, path, path\n",
    "\n",
    "path = path + '\\\\Data_Augmented'\n",
    "validation_path = og_path + '\\\\Lettuce'\n",
    "print('[INFO] Current Path:', og_path)\n",
    "print('[INFO] Loading data path... ', path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976136d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class_names = ['Bacterial', 'Fungal', 'No Disease Detected']\n",
    "\n",
    "img_size = (227, 227)\n",
    "size = 227\n",
    "batch_size = 64\n",
    "epochs = 30\n",
    "seed = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6331940c",
   "metadata": {},
   "source": [
    "As we use image_dataset_from_directory function that generates a dataset from the images in the given directory. We can set the image heights and widths to generally resize dimensions for all images to 227x227 pixels, which is part of image preprocessing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35296ac7",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Train Data')\n",
    "train_data = image_dataset_from_directory(\n",
    "    path,\n",
    "    image_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'training',\n",
    "    shuffle = True,\n",
    "    seed = seed,\n",
    ")\n",
    "\n",
    "print('\\nValidation Data')\n",
    "validation_data = image_dataset_from_directory(\n",
    "    validation_path,\n",
    "    image_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    validation_split = 0.2,\n",
    "    subset = 'validation',\n",
    "    shuffle = True,\n",
    "    seed = seed,\n",
    ")\n",
    "\n",
    "print('\\nTest Data')\n",
    "test_data = image_dataset_from_directory(\n",
    "    path,\n",
    "    image_size = img_size,\n",
    "    batch_size = batch_size,\n",
    "    shuffle = True,\n",
    "    seed = seed,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "14e48eec",
   "metadata": {},
   "source": [
    "### Hyper Parameters \n",
    "\n",
    "After numerous experimentations with various parameters, we use these as the optimal parameters preferable:\n",
    "    \n",
    "    batch_size = 64\n",
    "    epochs = 30\n",
    "    class_size = 3 \n",
    "    \n",
    "The primary preprocessing transformations that will be imposed on the data presented to the network are:\n",
    "- normalizing and standardizing the images\n",
    "- resizing all images that vary in dimensions to a 227x227 dimension. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99d41268",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_data(dataset):\n",
    "    plt.figure(figsize = (20, 20))\n",
    "    for images, labels in dataset.take(1):\n",
    "        for i in range(9):\n",
    "            ax = plt.subplot(3, 3, i + 1)\n",
    "            plt.imshow(images[i].numpy().astype('uint8'))\n",
    "            plt.title(class_names[labels[i]], fontsize = 20)\n",
    "            plt.axis('off')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc790ea9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_data(train_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0669d060",
   "metadata": {},
   "source": [
    "Subtle preprocessing using Keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74544e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_and_rescale = Sequential([\n",
    "    Resizing(size, size),\n",
    "    Rescaling(1./255)\n",
    "])\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "  RandomFlip('horizontal_and_vertical'),\n",
    "  RandomRotation(0.2),\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51788a5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "model.add(resize_and_rescale)\n",
    "model.add(data_augmentation)\n",
    "\n",
    "# model.add(Rescaling(1./ 255))\n",
    "\n",
    "model.add(Conv2D(96, 3, activation = 'relu', input_shape = (size, size, 3), strides = (4, 4)))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Conv2D(256, 3, activation = 'relu', strides = (1, 1), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
    "          \n",
    "model.add(Conv2D(384, 3, activation = 'relu', strides = (1, 1), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(384, 3, activation = 'relu', strides = (1, 1), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "# model.add(MaxPooling2D(pool_size = (3, 3), strides = (2, 2)))\n",
    "\n",
    "model.add(Conv2D(256, 3, activation = 'relu', strides = (1, 1), padding = 'same'))\n",
    "model.add(BatchNormalization())\n",
    "model.add(MaxPooling2D())\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(256, activation = 'relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(3, activation = 'sigmoid'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43e0da30",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = 'sgd',\n",
    "    loss = SparseCategoricalCrossentropy(),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84e77690",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "start = time.time()\n",
    "model.fit(\n",
    "    train_data,\n",
    "    validation_data = validation_data,\n",
    "    epochs = 30,\n",
    "    shuffle = True,\n",
    ")\n",
    "print('Time Lapsed:', str(round(time.time() - start, 4)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7177c3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f34ee886",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5af8af1e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f5ede4a6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
